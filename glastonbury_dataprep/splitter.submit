####################
#
# Example Job for HTCondor
#
####################

#---------------------------------------------
# Name your batch so it's easy to distinguish in the q.
JobBatchName = "PySceneSplitter"

# --------------------------------------------
# Executable and its arguments

#executable = /opt/conda/bin/python
executable = /vol/research/content_trading/amber_conda/envs/pytorch19/bin/python
arguments  = $ENV(PWD)/scenesplitter_ada.py --machine 'condor' --part 2

# ---------------------------------------------------
# Universe (vanilla, docker)
universe         = docker
#docker_image     = registry.eps.surrey.ac.uk/pytorch_env:pytorch
# docker_image     = nvidia/cuda:11.1.0-devel-ubuntu18.04
docker_image = pytorch/pytorch:latest
# docker_image     = registry.eps.surrey.ac.uk/dipu/pytorch19:neuralfb6
#docker_image     = registry.eps.surrey.ac.uk/dipu/pytorch19:cuda111
#
# -------------------------------------------------
# Event, out and error logs
log    = c$(cluster).p$(process).log
output = c$(cluster).p$(process).out
error  = c$(cluster).p$(process).error

# -----------------------------------
# File Transfer, Input, Output
should_transfer_files = YES

# -------------------------------------
# Requirements for the Job
# Use Storenext for faster file transfer - omit if using on orca which doesn't have any stornext machines
# Request a GPU with more that 4.5GB and less that 17GB of RAM
# Avoid old machines that can't run CUDA 9, 10, etc.

requirements = (HasStornext) 
    #(CUDAGlobalMemoryMb > 2000) && (CUDAGlobalMemoryMb <  10000) && \
    #(CUDACapability > 2.0)

# Clusters with project machines e.g cvssp-condor
# If you want to avoid ProjectOwned machine other that projects that you're part of, you can add:
# ((NotProjectOwned) || (machine == "mymachine1.eps.surrey.ac.uk") || (machine == "mymachine2.eps.surrey.ac.uk"))



# --------------------------------------
# Resources
request_GPUs     = 1
# this needs to be specified for the AI@Surrey cluster if requesting a GPU
+GPUMem          = 300
request_CPUs     = 4
request_memory   = 32G

#environment = "mount=$ENV(PWD),/vol/research/deepdiscover, "
#environment = "mount=$ENV(PWD), mount=/vol/research/deepdiscover"
#environment = "mount=$ENV(PWD), mount=/vol"
Environment =  "mount=/vol/research/content_trading,/vol/vssp/datasets/still/MSCOCO,/vol/research/NOBACKUP/"

#This job will complete in less than 1 hour
+JobRunTime = 35

#This job can checkpoint
+CanCheckpoint = true

# -----------------------------------
# Queue commands
queue 1
